{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EliU1c5dV5Aq"
   },
   "source": [
    "# **A Tutorial on \"A Joint Convolutional and Spatial Quad-Directional LSTM Network for Phase Unwrapping**\"\n",
    "\n",
    "**Malsha Perera** and **Ashwin De Silva**\n",
    "\n",
    "*Department of Electronics and Telecommunication Engineering, \n",
    "University of Moratuwa, Sri Lanka*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OC6nGoK9T8ug"
   },
   "source": [
    "# Welcome\n",
    "\n",
    "This tutorial walks you through the implementation of deep neural architecture introduced in the ICASSP 2021 conference paper titled \"[A Joint Convolutional and Spatial Quad-Directional LSTM Network for Phase Unwrapping](https://ieeexplore.ieee.org/document/9414748)\". For a detailed description about the methods and experiments carried out, the viewer is referred to the aforementioned paper. A video presentation about this work can be found [here](https://www.youtube.com/watch?v=RS5yPn5KHfU&t=680s).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6uf5mPlqRRKu"
   },
   "source": [
    "# Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aHa27OtnNG8C",
    "outputId": "e29e2f06-09f2-496a-f70a-deb7d7866be3"
   },
   "source": [
    "## Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLjC_6wJSLcR"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qMgnHNSCSI5J"
   },
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "mpl.style.use('default')\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import pylab as plt2\n",
    "from scipy.stats import gennorm, poisson, norm\n",
    "\n",
    "from keras.layers import Activation, BatchNormalization, Conv2D, UpSampling2D, Conv2DTranspose, concatenate\n",
    "from keras.layers import MaxPooling2D, Dropout, Input, AveragePooling2D, Reshape, Permute, UpSampling2D\n",
    "from keras.layers import SimpleRNN, Bidirectional, LSTM\n",
    "from keras.layers import Lambda\n",
    "from keras.models import load_model, Model\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.optimizers import *\n",
    "import keras.backend as K\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "K.set_image_data_format('channels_last')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wW0YPB3HSWro"
   },
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OQdoRU_6SaCa"
   },
   "source": [
    "def simulate(size, m_1, m_2, C, A, mu_x, mu_y, sigma_x, sigma_y):\n",
    "  \"\"\"\n",
    "  creates an arbitrary phase map by mixing gaussian blobs and adding ramps\n",
    "  \"\"\"\n",
    "  x = np.arange(0, size[0], 1)\n",
    "  y = np.arange(0, size[0], 1)\n",
    "  xx, yy = np.meshgrid(x, y, sparse=True)\n",
    "  I = np.zeros(size)\n",
    "  ## mix randomly shaped and placed gaussian blobs\n",
    "  for i in range(len(sigma_x)):\n",
    "      a = (xx-mu_x[i])**2/(2*sigma_x[i]**2) + (yy-mu_y[i])**2/(2*sigma_y[i]**2)\n",
    "      I += A[i]*np.exp(-a)\n",
    "  ## add ramp phase with random gradients and shifts\n",
    "  I = m_1*xx + m_2*yy + C + 0.1*I\n",
    "  return I\n",
    "\n",
    "def wrap(phi):\n",
    "  \"\"\"\n",
    "  wraps the true phase signal within [-pi, pi]\n",
    "  \"\"\"\n",
    "  return np.angle(np.exp(1j*phi))\n",
    "\n",
    "def rescale(im, range):\n",
    "  \"\"\"\n",
    "  mini-max rescales the input image\n",
    "  \"\"\"\n",
    "  im_std = (im - im.min()) / (im.max() - im.min())\n",
    "  im_scaled = im_std * (range[1] - range[0]) + range[0]\n",
    "  return im_scaled\n",
    "\n",
    "def create_random_image(size):\n",
    "  \"\"\"\n",
    "  creates an randomly simulated true phase map\n",
    "  \"\"\" \n",
    "  array_len = np.random.randint(2, 5)\n",
    "  m = np.random.uniform(0, 0.5, [2])\n",
    "  C = np.random.randint(1, 10)\n",
    "  A = np.random.randint(50, 1000, array_len)\n",
    "  mu_x = np.random.randint(20, 235, array_len)\n",
    "  mu_y = np.random.randint(20, 235, array_len)\n",
    "  sigma_x = np.random.randint(10, 45, array_len)\n",
    "  sigma_y = np.random.randint(10, 45, array_len)\n",
    "  I = simulate(size, m[0], m[1], C, A, mu_x, mu_y, sigma_x, sigma_y)\n",
    "  return I\n",
    "\n",
    "\n",
    "def plot(*argv, titles=None):\n",
    "  \"\"\"\n",
    "  plots a given number of phase maps\n",
    "  \"\"\"\n",
    "  if len(argv) == 1:\n",
    "    f, ax = plt.subplots(1, 1, sharey=True, figsize=(5, 5))\n",
    "    if titles is not None:\n",
    "      ax.set_title(titles)\n",
    "    a = ax.imshow(argv[0].squeeze(), cmap='jet')\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    f.colorbar(a, cax=cax)\n",
    "    plt.show()\n",
    "  else:\n",
    "    f, axes = plt.subplots(1, len(argv), sharey=True, figsize=(10, 10))\n",
    "    for i in range(len(argv)):\n",
    "        if titles is not None:\n",
    "          axes[i].set_title(titles[i])\n",
    "        a = axes[i].imshow(argv[i].squeeze(), cmap='jet')\n",
    "        divider = make_axes_locatable(axes[i])\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        f.colorbar(a, cax=cax)\n",
    "    plt.show()\n",
    "    f.colorbar(a, cax=cax)\n",
    "\n",
    "def plot_hist(*argv, titles):\n",
    "  \"\"\"\n",
    "  plots the historgram of the input phase maps\n",
    "  \"\"\"\n",
    "  for i in range(len(argv)):\n",
    "      hist = np.histogram(argv[i].ravel(), bins=100)\n",
    "      plt.plot(hist[1][1:], hist[0])\n",
    "  plt.xlabel(\"phase values\")\n",
    "  plt.ylabel(\"frequency\")\n",
    "  plt.title(\"Histogram Analysis\")\n",
    "  plt.grid()\n",
    "  if titles is not None:\n",
    "    plt.legend(titles)\n",
    "  plt.show()  \n",
    "\n",
    "def create_dataset(path, size, no_samples, max_lower_bound, max_upper_bound, noise_levels):\n",
    "  \"\"\"\n",
    "  creates the synthetic true-wrapped phase dataset\n",
    "  \"\"\"\n",
    "  wrapped_phase_maps = np.zeros((1, size[0], size[1]))\n",
    "  true_phase_maps = np.zeros((1, size[0], size[1])) \n",
    "\n",
    "  ## create dataset\n",
    "  for i in range(no_samples):\n",
    "      print(\"Creating {:n}/{:n} pairs\".format(i+1, no_samples))\n",
    "\n",
    "      ## generate the true and wrapped phase maps\n",
    "      I = create_random_image(size)\n",
    "      lower_bound = (-2) * np.pi * np.random.randint(1, max_lower_bound+1) \n",
    "      upper_bound = 2 * np.pi * np.random.randint(1, max_upper_bound+1) \n",
    "      I = rescale(I, [lower_bound, upper_bound])\n",
    "      I_wrap = wrap(I)\n",
    "\n",
    "      ## adding noise to the true phase before wrapping it\n",
    "      snr = noise_levels[np.random.randint(0, len(noise_levels))]\n",
    "      reqSNR = 10**(snr/10)\n",
    "      sigPower = 1\n",
    "      sigPower = 10**(sigPower/10)\n",
    "      noisePower = sigPower/reqSNR\n",
    "      I_gaun = np.sqrt(noisePower)*norm.rvs(0, 1, size=(256, 256)) # gaussian noise\n",
    "      I_n = I + I_gaun # noisy true phase\n",
    "      I_wrap_n = wrap(I_n) # noisy wrapped phase\n",
    "\n",
    "      wrapped_phase_maps = np.concatenate((wrapped_phase_maps, I_wrap_n.reshape(1, size[0], size[1])), axis=0)\n",
    "      true_phase_maps = np.concatenate((true_phase_maps, I.reshape(1, size[0], size[1])), axis=0)\n",
    "\n",
    "  ## save dataset\n",
    "  no_wrap_counts = max_lower_bound + max_upper_bound + 1\n",
    "  dataset_id = \"Noisy_Phase_Data_{:n}_{:n}pi_{:n}pi.hdf5\".format(no_samples, 2*max_lower_bound, 2*max_upper_bound)\n",
    "  dataset = h5py.File(os.path.join(path, dataset_id), mode='w')\n",
    "  dataset.create_dataset('psi', data=wrapped_phase_maps[1:, ...])\n",
    "  dataset.create_dataset('phi', data=true_phase_maps[1:, ...])\n",
    "  dataset.close()    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nH-uR57FiV-s"
   },
   "source": [
    "# Creating Simulated True Phase Maps\n",
    "\n",
    "The true phase maps are simulated by randomly setting the parameters of the following equation. \n",
    "\n",
    "$$ \\phi(x, y) = m_1 x + m_2 y + C + \\sum_{n=1}^{N} A_n \\exp \\Bigg[ - \\bigg( \\frac{(x - \\mu_x)^2}{2\\sigma_x^2} + \\frac{(y - \\mu_y)^2}{2\\sigma_y^2} \\bigg) \\Bigg] \\; ; \\; \\forall (x, y) \\in [-128, 127)^2$$ "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "R7Tw7qBWas8t",
    "outputId": "a44596db-69f8-46b3-8c88-769c481af4ce"
   },
   "source": [
    "## example\n",
    "size = (256, 256)\n",
    "I = create_random_image(size)\n",
    "I_wrap = wrap(I)\n",
    "plot(I, I_wrap, titles=[\"$\\phi$\", \"$\\psi$\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-yEZodYxnIls"
   },
   "source": [
    "# Creating Noisy Phase Dataset\n",
    "\n",
    "The noisy phase dataset is created by randomly adding the specified noise levels (SNRs in dB) to the simulated true phase images before wrapping them.\n",
    "\n",
    "The following code snippet generates a dataset with $1000$ true-wrapped phase maps of size $256 \\times 256$. The maximum and minimum values taken by the true phase map pixels are $2 N_u \\pi$ and $2 N_l \\pi$ respectively. Noise levels including $0, 5, 10, 20$ and $60 \\text{ dB}$ were randomly added to the true phase images before wrapping them. ($N_u = \\text{maximum upper bound}$, $N_l = \\text{maximum lower bound}$)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "evXjovTEdob-"
   },
   "source": [
    "## create the dataset\n",
    "save_path = '/content/drive/My Drive/DeepUnwrap'\n",
    "size = (256, 256)\n",
    "no_samples = 1000\n",
    "max_lower_bound = 4\n",
    "max_upper_bound = 4 \n",
    "noise_levels = [0, 5, 10, 20, 60]\n",
    "\n",
    "create_dataset(save_path, size, no_samples, max_lower_bound, max_upper_bound, noise_levels)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ypPCstZhuPTw"
   },
   "source": [
    "# Define the Joint Convolutional and SQD LSTM Archiecture\n",
    "\n",
    "In a nutshell, the architecture is comprised of a fully convolutional encoder-decoder network where the output of the\n",
    "encoder is passed through the proposed SQD-LSTM module\n",
    "before fed in to the decoder. The output feature map of the\n",
    "encoder is able to represent the local information of the input image. Feeding this encoder output to the SQD-LSTM\n",
    "module allows the network to learn the spatial dependencies\n",
    "between the local features contained in the encoder output.\n",
    "Subsequently, the output of SQD-LSTM module is fed in to\n",
    "the decoder network which increases the resolution of the output through transpose convolutional operations. Furthermore,\n",
    "in order to combine semantic features from the decoder layers and local features from the encoder layers, we add skip\n",
    "connections. Adding skip connections\n",
    "this way, ensures that the network assembles a more refined\n",
    "output at the later layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://drive.google.com/uc?id=1u0FBR0t0jw0zEuCplLuP_g05-Tm6k1r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://drive.google.com/uc?id=1qA-Vetv4ztFFhQBukHqHEdSPhH5zSVsA)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FSnMvloJuciY"
   },
   "source": [
    "def get_joint_conv_sqd_lstm_net():\n",
    "    \"\"\"\n",
    "    Defines the joint convoltional and spatial quad-directional LSTM network\n",
    "    \"\"\"\n",
    "    ## input to the network\n",
    "    input = Input((256, 256, 1))\n",
    "\n",
    "    ## encoder network\n",
    "    c1 = Conv2D(filters=16, kernel_size=(3,3), kernel_initializer='he_normal', padding='same')(input)\n",
    "    c1 = BatchNormalization()(c1)\n",
    "    c1 = Activation('relu')(c1)\n",
    "    p1 = AveragePooling2D()(c1)\n",
    "\n",
    "    c2 = Conv2D(filters=32, kernel_size=(3,3), kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = BatchNormalization()(c2)\n",
    "    c2 = Activation('relu')(c2)\n",
    "    p2 = AveragePooling2D()(c2)\n",
    "\n",
    "    c3 = Conv2D(filters=64, kernel_size=(3,3), kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = BatchNormalization()(c3)\n",
    "    c3 = Activation('relu')(c3)\n",
    "    p3 = AveragePooling2D()(c3)\n",
    "\n",
    "    c4 = Conv2D(filters=128, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = BatchNormalization()(c4)\n",
    "    c4 = Activation('relu')(c4)\n",
    "    p4 = AveragePooling2D()(c4)\n",
    "\n",
    "    # SQD-LSTM Block\n",
    "    x_hor_1 = Reshape((16 * 16, 128))(p4)\n",
    "    x_ver_1 = Reshape((16 * 16, 128))(Permute((2, 1, 3))(p4))\n",
    "\n",
    "    h_hor_1 = Bidirectional(LSTM(units=32, activation='tanh', return_sequences=True, go_backwards=False))(x_hor_1)\n",
    "    h_ver_1 = Bidirectional(LSTM(units=32, activation='tanh', return_sequences=True, go_backwards=False))(x_ver_1)\n",
    "\n",
    "    H_hor_1 = Reshape((16, 16, 64))(h_hor_1)\n",
    "    H_ver_1 = Permute((2, 1, 3))(Reshape((16, 16, 64))(h_ver_1))\n",
    "\n",
    "    c_hor_1 = Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                     kernel_initializer='he_normal', padding='same')(H_hor_1)\n",
    "    c_ver_1 = Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                     kernel_initializer='he_normal', padding='same')(H_ver_1)\n",
    "\n",
    "    H = concatenate([c_hor_1, c_ver_1])\n",
    "\n",
    "    # decoder Network\n",
    "    u5 = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(H)\n",
    "    u5 = concatenate([u5, c4])\n",
    "    c5 = Conv2D(filters=128, kernel_size=(3,3), kernel_initializer='he_normal', padding='same')(u5)\n",
    "    c5 = BatchNormalization()(c5)\n",
    "    c5 = Activation('relu')(c5)\n",
    "\n",
    "    u6 = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c3])\n",
    "    c6 = Conv2D(filters=64, kernel_size=(3,3), kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = BatchNormalization()(c6)\n",
    "    c6 = Activation('relu')(c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c2])\n",
    "    c7 = Conv2D(filters=32, kernel_size=(3,3), kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = BatchNormalization()(c7)\n",
    "    c7 = Activation('relu')(c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(16, (3, 3), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c1])\n",
    "    c8 = Conv2D(filters=32, kernel_size=(3,3), kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = BatchNormalization()(c8)\n",
    "    c8 = Activation('relu')(c8)\n",
    "\n",
    "    ## output layer\n",
    "    output = Conv2D(filters=1, kernel_size=(1, 1), padding='same', name='out1')(c8)\n",
    "    output = Activation('linear')(output)\n",
    "\n",
    "    model = Model(inputs=[input], outputs=[output])\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afXoYD2TzMBs"
   },
   "source": [
    "# Define the Composite Loss Function\n",
    "\n",
    "Since we formulate the phase unwrapping problem as a regression task, the go to choice for the loss function is Mean Squared Error (MSE) loss. However, our experiments revealed that MSE loss, when employed to the proposed network, shows an insufficient convergence that results in poor phase unwrapping performance. From $\\psi = \\angle e^{j\\phi}$, it follows that $\\phi + 2\\pi n$ where $\\forall n \\in \\mathbb{Z}$ gives rise to the same wrapped phase $\\psi$. Therefore, the phase unwrapping problem of $\\psi$ does not have a unique solution. Since MSE loss enforces the network to learn a unique solution, it does not fit well in to the nature of phase unwrapping problem. Hence, a loss function which allows for other solutions at convergence while increasing the similarity between the predicted phase $\\hat{\\phi}$ and true phase $\\phi$ is required. To address these concerns, we adopt the composite loss function $\\mathcal{L}_c$ defined below.\n",
    "\n",
    "$$\\mathcal{L}_c = \\lambda_1 \\mathcal{L}_{var} + \\lambda_2 \\mathcal{L}_{tv} $$\n",
    "where,\n",
    "$$\n",
    "    \\mathcal{L}_{var} = \\mathbb{E}\\big[(\\hat{\\phi} - \\phi)^2\\big] - \\big(\\mathbb{E} \\big[(\\hat{\\phi} - \\phi) \\big] \\big)^2\n",
    "$$\n",
    "$$\n",
    "    \\mathcal{L}_{tv} = \\mathbb{E}\\big[|\\hat{\\phi}_x - \\phi_x| + |\\hat{\\phi}_y - \\phi_y|\\big]\n",
    "$$\n",
    "and $\\lambda_1$, $\\lambda_2$ are the weights assigned for the two losses and were empirically set to 1 and 0.1 respectively during training. The variance of error loss $\\mathcal{L}_{var}$ allows for alternate solutions at convergence while the total variation of error loss $\\mathcal{L}_{tv}$ increases the similarity between $\\hat{\\phi}$ and $\\phi$ by enforcing the network to match the gradients of them."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "N_vEGKgH0OPS"
   },
   "source": [
    "def tv_loss_plus_var_loss(y_true, y_pred):\n",
    "  \"\"\"\n",
    "  Define the composite loss function that includes total variation of errors \n",
    "  loss and variance of errors loss\n",
    "  \"\"\"\n",
    "  # total variation loss\n",
    "  y_x = y_true[:, 1:256, :, :] - y_true[:, 0:255, :, :]\n",
    "  y_y = y_true[:, :, 1:256, :] - y_true[:, :, 0:255, :]\n",
    "  y_bar_x = y_pred[:, 1:256, :, :] - y_pred[:, 0:255, :, :]\n",
    "  y_bar_y = y_pred[:, :, 1:256, :] - y_pred[:, :, 0:255, :]\n",
    "  L_tv = K.mean(K.abs(y_x - y_bar_x)) + K.mean(K.abs(y_y - y_bar_y))\n",
    "\n",
    "  # variance of the error loss\n",
    "  E = y_pred - y_true\n",
    "  L_var = K.mean(K.mean(K.square(E), axis=(1, 2, 3)) - K.square(K.mean(E, axis=(1, 2, 3))))\n",
    "\n",
    "  loss = L_var + 0.1 * L_tv\n",
    "  return loss"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnh7duuMsPlk"
   },
   "source": [
    "# Load the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JTvNtk24p8FJ"
   },
   "source": [
    "## load the dataset \n",
    "dataset_id = 'Noisy_Phase_Data_1000_8pi_8pi'\n",
    "save_path = '/content/drive/MyDrive/DeepUnwrap/{}.hdf5'.format(dataset_id)\n",
    "dataset = h5py.File(save_path, mode='r')\n",
    "X = np.array(dataset['psi'])\n",
    "y = np.array(dataset['phi'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "zAC4zzHAszSQ",
    "outputId": "4a190dba-8c67-4a4a-a8e6-505581f62b84"
   },
   "source": [
    "## visualize a pair\n",
    "idx = np.random.randint(0, X.shape[0])\n",
    "plot(X[idx], y[idx], titles=[\"Noisy Wrapped Phase ($\\psi$)\", \"True Phase ($\\phi$)\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6N2gP0eT0j_6"
   },
   "source": [
    "# Compile the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I8vwoFcV0m6x",
    "outputId": "e62da418-f7d4-4aa5-8e14-ca845be65c97"
   },
   "source": [
    "model = get_joint_conv_sqd_lstm_net()\n",
    "model.summary()\n",
    "\n",
    "model_id = 'Model_{}'.format(dataset_id)\n",
    "model_path = '/content/drive/My Drive/DeepUnwrap/{}.h5'.format(model_id)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    loss=tv_loss_plus_var_loss\n",
    ")\n",
    "\n",
    "earlystopper = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=10,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    model_path,\n",
    "    monitor='loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQXioZFL3GBj"
   },
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "88wIP2zY1xRu",
    "outputId": "64aac23d-c15f-4bb2-9bc0-e75aca7b174d"
   },
   "source": [
    "## train the model\n",
    "history = model.fit(\n",
    "    x = X.reshape(X.shape[0], 256, 256, 1),\n",
    "    y = y.reshape(y.shape[0], 256, 256, 1),\n",
    "    batch_size=4,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[model_checkpoint, earlystopper]   \n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VpptK4pF-D_i"
   },
   "source": [
    "# Model Convergence"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "BUgczvYf34s7",
    "outputId": "1fb2030d-7da5-4b91-bb41-a57b64da346c"
   },
   "source": [
    "loss = history.history['loss']\n",
    "epochs = np.arange(0, len(loss), 1)\n",
    "plt.plot(epochs, loss)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Epochs vs. Loss\")\n",
    "plt.grid()\n",
    "plt.show"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzNgPPSaBPdJ"
   },
   "source": [
    "# (Create) and Load the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wKC0FbRCCIBt"
   },
   "source": [
    "## create a test dataset (run only once unless there's no need to create a new test set)\n",
    "save_path = '/content/drive/My Drive/DeepUnwrap'\n",
    "size = (256, 256)\n",
    "no_samples = 400\n",
    "max_lower_bound = 4\n",
    "max_upper_bound = 4 \n",
    "noise_levels = [0, 5, 10, 20, 60]\n",
    "\n",
    "create_dataset(save_path, size, no_samples, max_lower_bound, max_upper_bound, noise_levels)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8y6QlYd6CwHw"
   },
   "source": [
    "## load the test dataset \n",
    "dataset_id = 'Noisy_Phase_Data_400_8pi_8pi'\n",
    "save_path = '/content/drive/MyDrive/DeepUnwrap/{}.hdf5'.format(dataset_id)\n",
    "dataset = h5py.File(save_path, mode='r')\n",
    "X_test = np.array(dataset['psi'])\n",
    "y_test = np.array(dataset['phi'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "id": "IiHA7OXFC9cu",
    "outputId": "36c67be8-46d1-4a32-db70-c20a8e9b7d42"
   },
   "source": [
    "## visualize a pair\n",
    "idx = np.random.randint(0, X_test.shape[0])\n",
    "plot(X[idx], y[idx], titles=[\"Noisy Wrapped Phase (Test)\", \"True Phase (Test)\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLMCKOtKFE2G"
   },
   "source": [
    "# Predict True Phase from Wrapped Phase"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yNYvEVMW_ACJ"
   },
   "source": [
    "## load trained model\n",
    "model = get_joint_conv_sqd_lstm_net()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    metrics=[]\n",
    ")\n",
    "\n",
    "model_path = '/content/drive/MyDrive/DeepUnwrap/Model_Noisy_Phase_Data_1000_8pi_8pi.h5'\n",
    "model.load_weights(model_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xyKY6nT1FLjS"
   },
   "source": [
    "## predict true phase\n",
    "y_pred = model.predict(X_test, batch_size=4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGbM98OzMcAv"
   },
   "source": [
    "Due to the nature of the porblem of phase unwrapping, for each wrapped phase $\\psi$, there exists a family of solutions (true phases) charactersized by $\\phi + 2n\\pi, \\; n \\in \\mathbb{Z}$. To avoid this ambiguity when computing the accuracy metrics, we rescale the predicted true phase values ($\\hat{\\phi}$) to match scale of the true phase values ($\\phi$)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NQgNTgjHFv-1",
    "outputId": "e5cb2a61-f54a-480a-bcf6-0b841f348ed9"
   },
   "source": [
    "## visualize\n",
    "y_pred_scaled = np.empty((0, 256, 256))\n",
    "for i in range(10):\n",
    "  Xi = X_test[i]\n",
    "  yi = y_test[i]\n",
    "  ypi = y_pred[i]\n",
    "  \n",
    "  # match scales of predicted true phase\n",
    "  min1, max1 = np.min(yi), np.max(yi)\n",
    "  min2, max2 = np.min(ypi), np.max(ypi)\n",
    "  temp = (ypi - min2) / (max2 - min2)\n",
    "  ypi_scaled = temp * (max1 - min1) + min1\n",
    "  y_pred_scaled = np.vstack((y_pred_scaled, ypi_scaled.reshape(1, 256, 256)))\n",
    "\n",
    "  # visualize\n",
    "  plot(Xi, yi, ypi_scaled, titles=[\"Noisy Wrapped Phase ($\\psi$)\", \"True Phase ($\\phi$)\", \"Predicted True Phase ($\\hat{\\phi}$)\"])\n",
    "  plot_hist(yi, ypi_scaled, titles=[\"True Phase ($\\phi$)\", \"Predicted True Phase ($\\hat{\\phi}$)\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fkVMOpdMVd3"
   },
   "source": [
    "# Get Accuracy Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lENv_Yw-Npd3"
   },
   "source": [
    "We use Normalized Root Mean Squared Error (NRMSE) to report the performance of our method.\n",
    "\n",
    "$$ \\text{NRMSE} = \\frac{\\sqrt{\\mathbb{E}\\big[(\\phi - \\hat{\\phi})^2\\big]}}{\\phi_{max} - \\phi_{min}} $$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iclX7ottPAaf"
   },
   "source": [
    "## get the scaled predicted true phase values\n",
    "y_pred_scaled = np.empty((0, 256, 256))\n",
    "for i in range(X_test.shape[0]):\n",
    "  Xi = X_test[i]\n",
    "  yi = y_test[i]\n",
    "  ypi = y_pred[i]\n",
    "  \n",
    "  # match scales of predicted true phase\n",
    "  min1, max1 = np.min(yi), np.max(yi)\n",
    "  min2, max2 = np.min(ypi), np.max(ypi)\n",
    "  temp = (ypi - min2) / (max2 - min2)\n",
    "  ypi_scaled = temp * (max1 - min1) + min1\n",
    "  y_pred_scaled = np.vstack((y_pred_scaled, ypi_scaled.reshape(1, 256, 256)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zZUHq8UEHWyt",
    "outputId": "c8d22a71-4e45-4a5e-d021-44bb54199548"
   },
   "source": [
    "## compute NRMSE\n",
    "error = y_test - y_pred_scaled\n",
    "r = np.max(y_test, axis=(1, 2), keepdims=True) - np.min(y_test, axis=(1, 2), keepdims=True)\n",
    "NRMSE = np.mean(np.sqrt(np.mean(error**2, axis=(1, 2)))/r)*100\n",
    "performance = \"NRMSE = {:.2f} %\".format(NRMSE)\n",
    "print(performance)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3pdvX_OQH6L"
   },
   "source": [
    "# Citation\n",
    "If you use this work, please cite the following ICASSP 2021 conference paper.\n",
    "\n",
    "```@INPROCEEDINGS{9414748,  author={Perera, Malsha V. and De Silva, Ashwin},  booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},   title={A Joint Convolutional and Spatial Quad-Directional LSTM Network for Phase Unwrapping},   year={2021},  volume={},  number={},  pages={4055-4059},  doi={10.1109/ICASSP39728.2021.9414748}}```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i46s4702VuyW"
   },
   "source": [
    "$$ \\ast \\; \\ast \\; \\ast$$"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Joint_Conv_SQD_LSTM_for_Phase_Unwrapping.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
